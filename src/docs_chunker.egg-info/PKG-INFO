Metadata-Version: 2.4
Name: docs-chunker
Version: 0.1.0
Summary: Convert DOCX/PDF documents to Markdown and perform intelligent chunking for RAG systems
Author: Noam
License: MIT
Keywords: docx,pdf,markdown,chunking,rag,document-processing
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: markitdown>=0.0.1a26
Requires-Dist: typer>=0.12.0
Requires-Dist: pydantic>=2.0.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: rich>=13.9.2
Requires-Dist: fastapi>=0.115.0
Requires-Dist: httpx>=0.27.2
Provides-Extra: dev
Requires-Dist: pytest>=8.3.3; extra == "dev"
Requires-Dist: pytest-mock>=3.14.0; extra == "dev"
Requires-Dist: pytest-cov>=5.0.0; extra == "dev"
Requires-Dist: ruff>=0.6.9; extra == "dev"
Requires-Dist: black>=24.10.0; extra == "dev"
Requires-Dist: mypy>=1.13.0; extra == "dev"
Requires-Dist: pre-commit>=4.0.1; extra == "dev"

# Docs Chunker

A Python service that converts DOCX/PDF documents to Markdown and performs structure-aware chunking optimized for RAG (Retrieval-Augmented Generation) systems.

## Features

- **Document Conversion**: Converts DOCX files to Markdown using MarkItDown
- **Intelligent Chunking**: Structure-aware chunking based on document headings, sections, and subsections
- **Hebrew Support**: Full support for Hebrew/RTL text with proper UTF-8 handling
- **Configurable Token Limits**: Adjustable min/max token counts per chunk
- **YAML Front Matter**: Each chunk includes metadata (id, title, level, token_count, checksum)
- **Content Preservation**: Ensures no content loss during chunking

## Installation

```bash
# Clone the repository
git clone https://github.com/noamoss/docs-chunker.git
cd docs-chunker

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -e ".[dev]"

# Install DOCX support
pip install "markitdown[docx]"
```

## Usage

### CLI

```bash
# Convert and chunk a single DOCX file
python -m docs_chunker.cli documents/example.docx

# Convert and chunk all DOCX files in a directory
python -m docs_chunker.cli documents/

# With custom token limits
python -m docs_chunker.cli documents/example.docx --min-tokens 200 --max-tokens 1200

# Force overwrite existing outputs
python -m docs_chunker.cli documents/example.docx --force

# Dry run (preview without writing)
python -m docs_chunker.cli documents/example.docx --dry-run
```

### Output Structure

```
output/
└── <document-name>/
    ├── <document-name>.md          # Full markdown conversion
    └── chunks/
        ├── 001_<title-slug>.md     # Individual chunks with YAML front matter
        ├── 002_<title-slug>.md
        └── ...
```

Each chunk file contains:
- YAML front matter with metadata (id, title, level, token_count, checksum)
- Markdown content

## Development

```bash
# Run tests
make test
# or
pytest

# Run linters
make lint

# Format code
make fmt

# Type checking
make type
```

## Project Structure

```
docs-chunker/
├── src/docs_chunker/
│   ├── __init__.py
│   ├── cli.py              # CLI interface
│   ├── config.py           # Configuration settings
│   ├── convert.py          # DOCX to Markdown conversion
│   ├── chunk.py            # Chunking logic
│   ├── writer.py           # Chunk file writing
│   ├── io.py               # File I/O utilities
│   └── llm.py              # LLM validation (future)
├── tests/                  # Test suite
├── documents/              # Input documents (add your own)
└── output/                 # Generated outputs (gitignored)
```

## Chunking Strategy

The chunker uses a hierarchical approach:

1. **Heading-based partitioning**: Splits documents by markdown headings (#, ##, ###, etc.)
2. **Token-aware merging**: Merges undersized chunks (< min_tokens)
3. **Smart splitting**: Splits oversized chunks (> max_tokens) by:
   - Subheadings (if available)
   - Numbered lists (1., 2., etc.)
   - Bold headings (**text**)
   - Paragraph boundaries
4. **Title extraction**: Automatically extracts titles from headings or content

## Requirements

- Python >= 3.10
- markitdown (with [docx] extra for DOCX support)
- typer (for CLI)
- pydantic (for configuration)
- pyyaml (for chunk metadata)

## License

[Add your license here]

## Contributing

[Add contribution guidelines here]


